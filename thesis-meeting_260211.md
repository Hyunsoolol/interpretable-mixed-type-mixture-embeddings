# 시뮬레이션 연구: 계층적 페널티를 이용한 혼합 회귀 모형의 구조적 희소성 식별

## 1. 연구 개요

- **목적:** 고차원 혼합 회귀 모형(FMR)에서 변수 선택 및 **구조적 희소성(공통 효과 vs 이질적 효과) 식별 성능 검증.**
    
- **배경:** 샘플 수가 제한적($n=200$)이고 변수 차원이 높은($p=60$) 상황에서 제안 방법론(**Mix-HP-L**)과 기존 방법론(Mix-L, Mix-AL)의 성능 비교.
    
- **주안점:** 단순히 변수를 선택하는 것을 넘어, 집단 간 공통 구조(Common Structure)를 얼마나 정확히 파악하는지(FHR) 중점 평가.
    

---

## 2. 데이터 생성 과정 (DGP)

Li et al. (Biometrics)의 시뮬레이션 설정을 기반으로, **구조적 차이(Structural Difference)가 명확한 데이터셋** 생성.

### 2.1. 데이터 차원 및 설정

- **샘플 수 ($n$):** 200 (Small sample setting)
    
- **변수 수 ($p$):** 60 (High-dimensional setting)
    
- **잠재 집단 수 ($m$):** 3 (True $m=3$)
    
- **신호 대 잡음비 (SNR):** 50 (Clear signal environment)
    

### 2.2. 변수 구조 (True Structure)

60개 변수를 역할에 따라 세 그룹으로 구분하여 생성.

|**인덱스**|**역할 (Role)**|**계수 설정 (β)**|**특징**|
|---|---|---|---|
|**1~7**|**공통 효과** (Common)|$\beta_{jk} \neq 0, \beta_{diff}=0$|모든 집단에 **동일한 영향**을 미침.|
|**8~10**|**이질적 효과** (Hetero)|$\sum \beta_{jk} = 0$|집단마다 **서로 다른 영향** (예: $+3, -3, 0$).|
|**11~60**|**노이즈** (Noise)|$\beta_{jk} = 0$|실제 영향력 없음 (0).|

---

## 3. 비교 모형 (Competing Methods)

| **모형**                      | **방법론**                          | **특징 및 한계**                                        |
| --------------------------- | -------------------------------- | -------------------------------------------------- |
| **Mix-L**                   | Mixture + Lasso                  | 집단별 계수 독립 추정. **공통 구조 파악 불가.**                     |
| **Mix-AL**                  | Mixture + Adaptive Lasso         | 가중치 적용으로 변수 선택 강화. **초기값(Pilot) 민감도 높음.**          |
| **Mix-HP-L**<br>(Proposed)  | **Hierarchical Penalty + Lasso** | 계수를 공통($\alpha$)과 차이($\gamma$)로 분해. **구조적 식별 강점.** |
| **Mix-HP-AL**<br>(Proposed) | **Hierarchical Penalty + AL**    | Mix-HP-L에 가중치 결합. 이론상 최적이나 초기값 안정성 요구됨.            |

---

## 4. 시뮬레이션 파라미터 (Settings)

안정적인 결과 도출 및 논문 재현을 위해 **정밀 탐색(Fine Grid Search)** 및 **엄격한 수렴 기준**을 적용한 최종 설정을 사용함.

- **반복 횟수 ($R$):** 10회 (Trend Analysis)
    
- **탐색 범위 ($m$):** $[2, 3]$ (과소적합 vs 정답 식별 능력 테스트)
    
- **최적화 설정 (Rigorous Settings):**
    
    - `nlambda = 50`: **촘촘한 $\lambda$ 그리드 탐색**으로 최적의 BIC 지점 포착.
        
    - `lam_ratio = 1e-4`: 노이즈 제거를 위한 적절한 페널티 비율 유지.
        
    - `max_em = 100`, `tol_em = 1e-4`: EM 알고리즘의 충분한 수렴 보장.
        
    - `n_start = 20`: **초기값 의존성 최소화**를 위해 랜덤 스타트 횟수 대폭 증가.
        
    - `pilot_em = 30`: Adaptive Weights 산출을 위한 예비 조사 수행.
        

---

## 5. 실험 결과 및 해석

### 5.1. 성능 지표 요약

|**Method**|**Chosen m (Mode)**|**FHR (%)**|**MSE (β)**|**TPR (%)**|
|---|---|---|---|---|
|**Mix-L**|2 (Fail)|48.57|0.0596|45.0|
|**Mix-AL**|2 (Fail)|88.57|0.1293|82.0|
|**Mix-HP-L**|**3 (Success)**|**2.86**|**0.0010**|**100.0**|
|**Mix-HP-AL**|**3 (Success)**|50.00|0.1705|90.0|

> **지표 설명:**
> 
> - **Chosen $m$:** BIC 기준 최적 집단 수 (정답: 3).
>     
> - **FHR (False Hetero Rate):** 공통 변수인데 이질적 변수라고 잘못 판단한 비율 (**낮을수록 우수**).
>     
> - **MSE:** 추정된 회귀 계수의 오차 (**낮을수록 우수**).
>     
> - **TPR (True Positive Rate):** 실제 중요 변수를 정확히 선택한 비율 (**높을수록 우수**).
>     

### 5.2. 결과 해석

**1. 제안 방법(Mix-HP-L)의 압도적 우위 입증**

- **완벽한 구조 식별:** 정밀한 파라미터 설정 하에서 **Mix-HP-L**은 정답 집단 수($m=3$)를 정확히 맞췄을 뿐만 아니라, **FHR 2.86%**라는 매우 낮은 수치를 기록함. 이는 모델이 **변수의 공통 구조(Common Structure)를 거의 완벽하게 파악**했음을 의미함.
    
- **초정밀 추정:** 구조를 정확히 파악함에 따라 MSE 또한 **0.0010**으로, 타 모델 대비 **정밀한 추정 성능**을 보임.
    

**2. Mix-HP-AL의 성과와 한계**

- **집단 수 식별 성공:** 초기값 시도 횟수를 증가(`n_start=20`)시킨 결과, Mix-HP-AL도 **$m=3$을 찾아내는 데 성공**함 (기존 $m=2$ 실패 극복).
    
- **여전한 구조적 불안정성:** 그러나 $m$은 맞췄음에도 불구하고 **FHR은 50.0%**로 높게 나타남. 이는 Mix-HP-AL이 집단 수는 맞췄으나, **'어떤 변수가 공통적인지'를 구별하는 능력은 Mix-HP-L에 비해 현저히 떨어짐**을 시사함. 또한 MSE(0.1705)가 높아 과적합(Overfitting) 경향을 보임.
    

---

## 6. 결론 (Conclusion)

- **Mix-HP-L의 강건성(Robustness):** 별도의 가중치(Adaptive Weights) 없이 **구조적 페널티(Hierarchical Penalty)**만으로 작동하는 Mix-HP-L이, 데이터가 적고($n=200$) 복잡한 고차원 환경에서 **가장 정확하고 안정적인 성능(Lowest FHR & MSE)**을 보임을 최종 확인함.
    
- **모델 선택 제언:** Adaptive 방법론(Mix-HP-AL)은 튜닝을 통해 집단 수 식별 개선이 가능하나, **구조적 희소성(Structural Sparsity)을 정확히 파악하고 정밀한 계수를 추정**하는 데 있어서는 **Mix-HP-L이 가장 신뢰할 수 있는 최적의 모델**임.


## Appendix. 추가 시뮬레이션 시나리오 분석 (Sensitivity Analysis)

본 연구에서는 최종 설정(Main Result)을 도출하기 위해, 주요 하이퍼파라미터(`pilot_em`, `n_start`, `lam_ratio`) 변화에 따른 모델의 민감도 분석을 수행하였다. 다음은 대표적인 3가지 추가 시나리오의 결과이다.

### Case A. 리소스 제약 환경 (Fast Run Setting)

계산 효율성을 위해 반복 횟수와 초기화 과정을 최소화한 설정.

- **Key Parameters:** `n_start=3`, `pilot_em=15`, `nlambda=18`
    
- **결과 요약:**
    
    - **Mix-HP-L**은 이러한 열악한 환경에서도 **정답($m=3$)과 낮은 FHR(5.7%)**을 기록하며 강건함을 증명함.
        
    - 반면, **Mix-HP-AL**은 초기값 불안정으로 인해 **과소적합($m=2$)** 발생.
        

|**Method**|**Chosen m**|**FHR (%)**|**MSE (β)**|**TPR (%)**|
|---|---|---|---|---|
|Mix-L|2|41.43|0.0646|38.0|
|Mix-AL|2|70.00|0.0513|65.0|
|**Mix-HP-L**|**3**|**5.71**|**0.0278**|76.0|
|Mix-HP-AL|2|7.14|0.0387|80.0|

### Case B. 과적합 발생 시나리오 (Overfitting Case)

Adaptive Lasso의 성능 향상을 위해 규제(Penalty)를 약하게 설정한 경우.

- **Key Parameters:** `lam_ratio=1e-5` (Weak Penalty), `pilot_em=100`
    
- **결과 요약:**
    
    - **Mix-HP-AL**이 집단 수($m=3$)를 찾는 데는 성공했으나, 노이즈를 제대로 제거하지 못해 **MSE(0.1582)가 급증**하고 **FHR(51.4%)이 악화**됨.
        
    - 이는 적절한 수준의 규제(`1e-4`)가 필수적임을 시사함.
        

|**Method**|**Chosen m**|**FHR (%)**|**MSE (β)**|**TPR (%)**|
|---|---|---|---|---|
|Mix-L|2|50.00|0.0571|47.0|
|Mix-AL|3|88.57|0.2332|86.0|
|**Mix-HP-L**|**3**|**5.71**|**0.0009**|**100.0**|
|Mix-HP-AL|**3**|51.43|0.1582|93.0|

---

### Case C. 초기값 불충분 시나리오 (Insufficient Pilot)

정밀도(`nlambda=50`)는 높였으나, Pilot 단계의 반복 횟수가 부족했던 경우.

- **Key Parameters:** `nlambda=50` (High Precision), `pilot_em=30` (Short Pilot)
    
- **결과 요약:**
    
    - **Mix-HP-L**은 정밀 설정 덕분에 **FHR 2.86%, MSE 0.0010**이라는 최상의 성능을 보임.
        
    - **Mix-HP-AL**은 본 학습 설정이 정밀함에도 불구하고, Pilot 단계의 정보 부족으로 다시 **$m=2$로 실패**함. 이는 `pilot_em`의 확보가 선결 조건임을 보여줌.
        

|**Method**|**Chosen m**|**FHR (%)**|**MSE (β)**|**TPR (%)**|
|---|---|---|---|---|
|Mix-L|2|48.57|0.0596|45.0|
|Mix-AL|2|88.57|0.1293|82.0|
|**Mix-HP-L**|**3**|**2.86**|**0.0010**|**100.0**|
|Mix-HP-AL|2|50.00|0.1705|90.0|
