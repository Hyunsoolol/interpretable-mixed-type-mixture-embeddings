# 시뮬레이션 연구 보고서: 계층적 페널티를 이용한 혼합 회귀 모형의 구조적 희소성 식별

## 1. 연구 개요

- **목적:** 고차원 혼합 회귀 모형(FMR)에서 변수 선택 및 **구조적 희소성(공통 효과 vs 이질적 효과) 식별 성능 검증.**
    
- **배경:** 샘플 수가 제한적($n=200$)이고 변수 차원이 높은($p=60$) 상황에서 제안 방법론(**Mix-HP-L**)과 기존 방법론(Mix-L, Mix-AL)의 성능 비교.
    
- **주안점:** 단순히 변수를 선택하는 것을 넘어, 집단 간 공통 구조(Common Structure)를 얼마나 정확히 파악하는지(FHR) 중점 평가.
    

---

## 2. 데이터 생성 과정 (DGP)

Li et al. (Biometrics)의 시뮬레이션 설정을 기반으로, **구조적 차이(Structural Difference)가 명확한 데이터셋** 생성.

### 2.1. 데이터 차원 및 설정

- **샘플 수 ($n$):** 200 (Small sample setting)
    
- **변수 수 ($p$):** 60 (High-dimensional setting)
    
- **잠재 집단 수 ($m$):** 3 (True $m=3$)
    
- **신호 대 잡음비 (SNR):** 50 (Clear signal environment)
    

### 2.2. 변수 구조 (True Structure)

60개 변수를 역할에 따라 세 그룹으로 구분하여 생성.

|**인덱스**|**역할 (Role)**|**계수 설정 (β)**|**특징**|
|---|---|---|---|
|**1~7**|**공통 효과** (Common)|$\beta_{jk} \neq 0, \beta_{diff}=0$|모든 집단에 **동일한 영향**을 미침.|
|**8~10**|**이질적 효과** (Hetero)|$\sum \beta_{jk} = 0$|집단마다 **서로 다른 영향** (예: $+3, -3, 0$).|
|**11~60**|**노이즈** (Noise)|$\beta_{jk} = 0$|실제 영향력 없음 (0).|

---

## 3. 비교 모형 (Competing Methods)

| **모형**                      | **방법론**                          | **특징 및 한계**                                        |
| --------------------------- | -------------------------------- | -------------------------------------------------- |
| **Mix-L**                   | Mixture + Lasso                  | 집단별 계수 독립 추정. **공통 구조 파악 불가.**                     |
| **Mix-AL**                  | Mixture + Adaptive Lasso         | 가중치 적용으로 변수 선택 강화. **초기값(Pilot) 민감도 높음.**          |
| **Mix-HP-L**<br>(Proposed)  | **Hierarchical Penalty + Lasso** | 계수를 공통($\alpha$)과 차이($\gamma$)로 분해. **구조적 식별 강점.** |
| **Mix-HP-AL**<br>(Proposed) | **Hierarchical Penalty + AL**    | Mix-HP-L에 가중치 결합. 이론상 최적이나 초기값 안정성 요구됨.            |

---

## 4. 시뮬레이션 파라미터 (Settings)

안정적인 결과 도출 및 논문 재현을 위해 **정밀 탐색(Fine Grid Search)** 및 **엄격한 수렴 기준** 적용.

- **반복 횟수 ($R$):** 50회 (안정적 평균 산출)
    
- **탐색 범위 ($m$):** $[2, 3]$ (과소적합 vs 정답 식별 능력 테스트)
    
- **최적화 설정:**
    
    - `nlambda = 50`: 촘촘한 $\lambda$ 그리드 탐색.
        
    - `max_em = 100`, `tol_em = 1e-5`: EM 알고리즘 수렴 기준 강화.
        
    - `n_start = 20`: 초기값 의존성 최소화를 위한 다중 랜덤 스타트.
        
    - `pilot_em = 30`: Adaptive Weights 산출을 위한 예비 조사 수행.
        

---

## 5. 실험 결과 및 해석

### 5.1. 성능 지표 요약

|**Method**|**Chosen m (Mode)**|**FHR (%)**|**MSE (β)**|**TPR (%)**|
|---|---|---|---|---|
|**Mix-L**|2 (Fail)|41.43|0.0646|38.0|
|**Mix-AL**|2 (Fail)|70.00|0.0513|65.0|
|**Mix-HP-L**|**3 (Success)**|**2.86**|**0.0278**|**76.0**|
|**Mix-HP-AL**|2 (Fail)|7.14|0.0387|80.0|

> - **Chosen $m$:** BIC 기준 최적 집단 수 (정답: 3)
>     
> - **FHR (False Hetero Rate):** 공통 변수를 이질적 변수로 오분류한 비율 (**낮을수록 우수**)
>     
> - **MSE:** 계수 추정 오차 (**낮을수록 우수**)
>     

### 5.2. 결과 해석

**1. 제안 방법(Mix-HP-L)의 강건성 입증**

- **집단 수 식별:** $n=200$의 제한적 상황에서 타 모델들이 $m=2$로 과소적합(Under-fitting)된 반면, **Mix-HP-L만이 유일하게 정답($m=3$)을 정확히 식별함.**
    
- **구조적 희소성 달성:** FHR 2.86%를 기록, 공통 변수(Common Effect)를 거의 완벽하게 구분해냄. (Mix-AL의 70%와 대조적)
    

**2. Adaptive 방법론의 한계점 확인**

- **초기값 불안정성:** 이론적으로 우수한 Mix-AL, Mix-HP-AL이 부진한 원인은 **Pilot 단계의 오류**에 기인함.
    
- 샘플 부족으로 예비 조사(Pilot) 단계에서 집단 수를 2개로 오판, 잘못된 가중치(Penalty Weight)가 본 학습에 영향을 미쳐 $m=2$로 수렴.
    

---

## 6. 결론 (Conclusion)

- **구조 식별 능력:** Mix-HP-L은 외부 가중치 없이 구조적 페널티만으로 **집단 간 공통 구조를 효과적으로 파악**함이 확인됨.
    
- **데이터 효율성:** 샘플 수가 적고 차원이 높은 환경에서 Adaptive 방식보다 **초기값에 덜 민감하며 안정적인 성능**을 보임.
    
- **최종 제언:** 데이터가 충분하지 않은 고차원 분석 환경에서는 **Mix-HP-L**이 가장 신뢰할 수 있는 선택지임을 시사함.
