# 시뮬레이션 연구 보고서: 계층적 페널티를 이용한 혼합 회귀 모형의 구조적 희소성 식별

## 1. 연구 개요

- **목적:** 고차원 혼합 회귀 모형(FMR)에서 변수 선택 및 **구조적 희소성(공통 효과 vs 이질적 효과) 식별 성능 검증.**
    
- **배경:** 샘플 수가 제한적($n=200$)이고 변수 차원이 높은($p=60$) 상황에서 제안 방법론(**Mix-HP-L**)과 기존 방법론(Mix-L, Mix-AL)의 성능 비교.
    
- **주안점:** 단순히 변수를 선택하는 것을 넘어, 집단 간 공통 구조(Common Structure)를 얼마나 정확히 파악하는지(FHR) 중점 평가.
    

---

## 2. 데이터 생성 과정 (DGP)

Li et al. (Biometrics)의 시뮬레이션 설정을 기반으로, **구조적 차이(Structural Difference)가 명확한 데이터셋** 생성.

### 2.1. 데이터 차원 및 설정

- **샘플 수 ($n$):** 200 (Small sample setting)
    
- **변수 수 ($p$):** 60 (High-dimensional setting)
    
- **잠재 집단 수 ($m$):** 3 (True $m=3$)
    
- **신호 대 잡음비 (SNR):** 50 (Clear signal environment)
    

### 2.2. 변수 구조 (True Structure)

60개 변수를 역할에 따라 세 그룹으로 구분하여 생성.

|**인덱스**|**역할 (Role)**|**계수 설정 (β)**|**특징**|
|---|---|---|---|
|**1~7**|**공통 효과** (Common)|$\beta_{jk} \neq 0, \beta_{diff}=0$|모든 집단에 **동일한 영향**을 미침.|
|**8~10**|**이질적 효과** (Hetero)|$\sum \beta_{jk} = 0$|집단마다 **서로 다른 영향** (예: $+3, -3, 0$).|
|**11~60**|**노이즈** (Noise)|$\beta_{jk} = 0$|실제 영향력 없음 (0).|

---

## 3. 비교 모형 (Competing Methods)

| **모형**                      | **방법론**                          | **특징 및 한계**                                        |
| --------------------------- | -------------------------------- | -------------------------------------------------- |
| **Mix-L**                   | Mixture + Lasso                  | 집단별 계수 독립 추정. **공통 구조 파악 불가.**                     |
| **Mix-AL**                  | Mixture + Adaptive Lasso         | 가중치 적용으로 변수 선택 강화. **초기값(Pilot) 민감도 높음.**          |
| **Mix-HP-L**<br>(Proposed)  | **Hierarchical Penalty + Lasso** | 계수를 공통($\alpha$)과 차이($\gamma$)로 분해. **구조적 식별 강점.** |
| **Mix-HP-AL**<br>(Proposed) | **Hierarchical Penalty + AL**    | Mix-HP-L에 가중치 결합. 이론상 최적이나 초기값 안정성 요구됨.            |

---

## 4. 시뮬레이션 파라미터 (Settings)

안정적인 결과 도출 및 논문 재현을 위해 **정밀 탐색(Fine Grid Search)** 및 **엄격한 수렴 기준** 적용.

- **반복 횟수 ($R$):** 50회 (안정적 평균 산출)
    
- **탐색 범위 ($m$):** $[2, 3]$ (과소적합 vs 정답 식별 능력 테스트)
    
- **최적화 설정:**
    
    - `nlambda = 50`: 촘촘한 $\lambda$ 그리드 탐색.
        
    - `max_em = 100`, `tol_em = 1e-5`: EM 알고리즘 수렴 기준 강화.
        
    - `n_start = 20`: 초기값 의존성 최소화를 위한 다중 랜덤 스타트.
        
    - `pilot_em = 30`: Adaptive Weights 산출을 위한 예비 조사 수행.
        

---

## 5. 실험 결과 및 해석

### 5.1. 성능 지표 요약

| **Method**    | **Chosen m (Mode)** | **FHR (%)** | **MSE (β)** | **TPR (%)** |
| ------------- | ------------------- | ----------- | ----------- | ----------- |
| **Mix-L**     | 2 (Fail)            | 41.43       | 0.0646      | 38.0        |
| **Mix-AL**    | 2 (Fail)            | 70.00       | 0.0513      | 65.0        |
| **Mix-HP-L**  | **3 (Success)**     | **2.86**    | **0.0278**  | 76.0        |
| **Mix-HP-AL** | 2 (Fail)            | 7.14        | 0.0387      | **80.0**    |


- **Chosen $m$:** BIC 기준 최적 집단 수 (정답: 3).
    
- **FHR (False Hetero Rate):** 공통 변수인데 이질적 변수라고 잘못 판단한 비율 (**낮을수록 우수**).
    
- **MSE:** 추정된 회귀 계수의 오차 (**낮을수록 우수**).
    
- **TPR (True Positive Rate):** 실제 중요 변수를 정확히 선택한 비율 (**높을수록 우수**).
        
### 5.2. 결과 해석

**1. 제안 방법(Mix-HP-L)의 강건성(Robustness) 입증**

- **집단 수 식별:** 제한적인 계산 설정(`n_start=3`)과 샘플 수($n=200$)에서도, **Mix-HP-L만이 유일하게 정답($m=3$)을 정확히 식별함.** (타 모델은 모두 $m=2$로 과소적합).
    
- **구조적 희소성 달성:** **FHR 2.86%**를 기록, 공통 변수(Common Effect)를 거의 완벽하게 구분해냄. 이는 Mix-AL(70%)이나 Mix-L(41%) 대비 압도적인 성능임.
    
- **정확도(MSE):** 구조를 정확히 파악함에 따라 계수 추정 오차(MSE) 또한 **0.0278**로 가장 낮게 나타남.
    

**2. Adaptive 방법론의 한계점 확인**

- **Mix-HP-AL의 부진 원인:** 이론적으로 가장 우수해야 할 Mix-HP-AL이 $m=2$를 선택한 이유는 **Pilot 단계의 설정(`pilot_em=15`)** 때문임.
    
- 짧은 예비 조사로 인해 초기 가중치가 $m=2$ 방향으로 편향되었고, 이것이 본 학습에 영향을 미침. 이는 Adaptive 방법론이 **초기값 설정에 민감**함을 시사함.
    

---

## 6. 결론 (Conclusion)

- **Mix-HP-L의 우수성:** 별도의 가중치(Weight)나 복잡한 초기화 과정 없이, **구조적 페널티(Structural Penalty)만으로도 집단 간 공통 구조를 효과적으로 파악**함이 입증됨.
    
- **실용적 가치:** 계산 리소스가 제한적이거나 데이터가 불충분한 상황(Small $n$)에서는, 민감한 Adaptive 방식보다 **Mix-HP-L이 훨씬 안정적이고 신뢰할 수 있는 선택지**임을 확인.
    
- **향후 계획:** 추후 `pilot_em` 및 `n_start`를 증가시킨 정밀 실험을 통해 Mix-HP-AL의 성능 향상 여부를 추가 검증할 예정.
